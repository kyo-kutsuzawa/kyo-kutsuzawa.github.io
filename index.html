<!DOCTYPE html>
<html>

<head>
    <meta charset="UTF-8">
    <meta name="description" content="Kyo Kutsuzawa's web page. A researcher in robotics, motor learning, and force-signal processing. Assistant professor at Department of Robotics, Graduate School of Engineering, Tohoku University.">
    <meta name="viewport" content="width=device-width,initial-scale=1.0">
    <meta name="google-site-verification" content="BNIh0sk5LDWfaNTaJpZBNsYaQliTrYdOsbolLAvC-Ps">
    <title>kyo-kutsuzawa.github.io</title>
    <link href="mystyle.css" rel="stylesheet" type="text/css" />
</head>

<body>
    <header id="home">
        <h1>kyo-kutsuzawa</h1>
        <nav>
            <a href="#home">Home</a>
            <a href="#research">Research</a>
            <a href="#resource">Resources</a>
            <a href="#publication">Publications</a>
            <a href="#achievements">Achievements</a>
            <a href="#contact" >Contact</a>
        </nav>
    </header>
    <main>
        <section id="research">
            <h1>Research</h1>

            <p>(Details are in Japanese)</p>

            <p class="research_item" id="imitation-learning-synergies">
                <a href="research/imitation-learning-synergies.html">
                    <span>Imitation learning with <i>synergies</i></span>
                </a>
            </p>

            <p class="research_item" id="movement-generation-seq2seq">
                <a href="research/movement-generation-seq2seq.html">
                    <span>Movement generation with seq2seq models</span>
                </a>
            </p>

            <p class="research_item" id="force-signal-processing">
                <a href="research/force-signal-processing.html">
                    <span>Force-signal processing</span>
                </a>
            </p>

            <p class="research_item" id="robotic-tool-use">
                <a href="research/robotic-tool-use.html">
                    <span>Robot control for tool use</span>
                </a>
            </p>
        </section>

        <section id="resource">
            <h1>Resources</h1>

            <p>
                <a class="item tile" href="https://kyo-kutsuzawa.github.io/technical-note/">
                    Technical notes
                </a>
            </p>

            <p>
                <a class="item tile" href="https://kyo-kutsuzawa.github.io/math-preview/">
                    Real-time preview of mathematical codes in LaTeX style
                </a>
            </p>

            <p>
                <a class="item tile" href="https://github.com/kyo-kutsuzawa/ieej-beast">
                    BiBTeX style for the Institute of Electrical Engineers of Japan (unofficial)
                </a>
            </p>

            <p>
                <a class="item tile" href="https://github.com/kyo-kutsuzawa/tuiplot">
                    Plotting tool with text-based user interface
                </a>
            </p>

            <p>
                <a class="item tile" href="https://github.com/kyo-kutsuzawa/synergy-extraction/">
                    Extraction of time-varying synergies
                </a>
            </p>

            <p>
                <a class="item tile" href="https://kyo-kutsuzawa.github.io/pomodoro-timer">
                    Pomodoro timer
                </a>
            </p>

            <p>
                <a class="item tile" href="https://github.com/kyo-kutsuzawa/ieejconf">
                    LaTeX template for IEEJ domestic conference (unofficial)
                </a>
            </p>
        </section>

        <section id="publication">
            <h1>Publications</h1>

            <section>
                <h2>Journal Papers</h2>

                <ol>
                    <li>Taku Sugiyama, Kyo Kutsuzawa, Dai Owaki, Elijah Almanzor, Fumiya Iida, and Mitsuhiro Hayashibe, &ldquo;Versatile Graceful Degradation Framework for Bio-inspired Proprioception with Redundant Soft Sensors,&rdquo; Frontiers in Robotics and AI. (Accepted)</li>
                    <li>Takumi Matsumura, Eiji Inomata, Kyo Kutsuzawa, Dai Owaki, and Mitsuhiro Hayashibe, &ldquo;Muscle Control Analysis of Human Walking and Cycling in Speed and Load Variations with Time-Varying Synergy,&rdquo; IEEE Sensors Journal. DOI: <a href="https://doi.org/10.1109/JSEN.2024.3486294">10.1109/JSEN.2024.3486294</a> (Early Access) <br>Corresponding author: Kyo Kutsuzawa and Mitsuhiro Hayashibe</li>
                    <li>Kyo Kutsuzawa, Minami Matsumoto, Dai Owaki, and Mitsuhiro Hayashibe, &ldquo;Learning-based Object's Stiffness and Shape Estimation with Confidence Level in Multi-Fingered Hand Grasping,&rdquo; Frontiers in Neurorobotics, Vol. 18, 2024. DOI: <a href="https://doi.org/10.3389/fnbot.2024.1466630">10.3389/fnbot.2024.1466630</a> (Open Access)</li>
                    <li>Akito Fukunishi, Kyo Kutsuzawa, Dai Owaki, and Mitsuhiro Hayashibe, &ldquo;Synergy quality assessment of muscle modules for determining learning performance using a realistic musculoskeletal model,&rdquo; Frontiers in Computational Neuroscience, Vol. 18, 2024. DOI: <a href="https://doi.org/10.3389/fncom.2024.1355855">10.3389/fncom.2024.1355855</a> (Open Access)</li>
                    <li>Kenya Tada, Yuhei Sorimachi, Kyo Kutsuzawa, Dai Owaki, and Mitsuhiro Hayashibe, &ldquo;Integrated Quantitative Evaluation of Spatial Cognition and Motor Function with HoloLens Mixed Reality,&rdquo; Sensors, vol. 24, no. 2, p. 528, 2024. DOI: <a href="https://doi.org/10.3390/s24020528">10.3390/s24020528</a> (Open Access)</li>
                    <li>Taku Sugiyama, Kyo Kutsuzawa, Dai Owaki, and Mitsuhiro Hayashibe, &ldquo;Latent Representation-based Learning Controller for Pneumatic and Hydraulic Dual Actuation of Pressure-driven Soft Actuators,&rdquo; Soft Robotics, vol. 11, no. 1, pp. 105–117, 2023. DOI: <a href="https://doi.org/10.1089/soro.2022.0224">10.1089/soro.2022.0224</a> (Open Access)</li>
                    <li>Muhammad Hannan Ahmed, Kyo Kutsuzawa, and Mitsuhiro Hayashibe, &ldquo;Transhumeral Arm Reaching Motion Prediction through Deep Reinforcement Learning-Based Synthetic Motion Cloning,&rdquo; Biomimetics, vol. 8, no. 4, 2023. DOI: <a href="https://doi.org/10.3390/biomimetics8040367">10.3390/biomimetics8040367</a> (Open Access)</li>
                    <li>Wei Zhu, Xian Guo, Dai Owaki, Kyo Kutsuzawa, and Mitsuhiro Hayashibe, &ldquo;A Survey of Sim-to-Real Transfer Techniques applied to Reinforcement Learning for Bio-Inspired Robots,&rdquo; IEEE Transactions on Neural Networks and Learning Systems, vol. 34, no. 7, pp. 3444–3459 2023. DOI: <a href="https://doi.org/10.1109/TNNLS.2021.3112718">10.1109/TNNLS.2021.3112718</a></li>
                    <li>Kyo Kutsuzawa and Mitsuhiro Hayashibe, &ldquo;Imitation Learning with Time-Varying Synergy for Compact Representation of Spatiotemporal Structures,&rdquo; IEEE Access, vol. 11, pp. 34150-34162, 2023. DOI: <a href="https://doi.org/10.1109/ACCESS.2023.3264213">10.1109/ACCESS.2023.3264213</a> (Open Access)</li>
                    <li>Shunsuke Koseki, Kyo Kutsuzawa, Dai Owaki, and Mitsuhiro Hayashibe, &ldquo;Multimodal Bipedal Locomotion Generation with Passive Dynamics via Deep Reinforcement Learning,&rdquo; Frontiers in Neurorobotics, vol. 16, 2023. DOI: <a href="https://doi.org/10.3389/fnbot.2022.1054239">10.3389/fnbot.2022.1054239</a> (Open Access)</li>
                    <li>Kyo Kutsuzawa and Mitsuhiro Hayashibe, &ldquo;Motor Synergy Generalization Framework for New Targets in Multi-planar and Multi-directional Reaching Task,&rdquo; Royal Society Open Science, vol. 9, no. 5, p. 211721, 2022. DOI: <a href="https://doi.org/10.1098/rsos.211721">10.1098/rsos.211721</a> (Open Access)</li>
                    <li>Katsumi Naya, Kyo Kutsuzawa, Dai Owaki, and Mitsuhiro Hayashibe, &ldquo;Spiking Neural Network Discovers Energy-efficient Hexapod Motion in Deep Reinforcement Learning,&rdquo; IEEE Access, vol. 9, pp. 150345–150354, 2021. DOI: <a href="https://doi.org/10.1109/ACCESS.2021.3126311">10.1109/ACCESS.2021.3126311</a> (Open Access)</li>
                    <li>Taku Sugiyama, Kyo Kutsuzawa, Dai Owaki, and Mitsuhiro Hayashibe, &ldquo;Individual deformability compensation of soft hydraulic actuators through iterative learning-based neural network,&rdquo; Bioinspiration and Biomimetics, vol. 16, no. 5, p. 056016, 2021. DOI: <a href="https://doi.org/10.1088/1748-3190/ac1b6f">10.1088/1748-3190/ac1b6f</a> (Open Access)</li>
                    <li>Masahide Oikawa, Tsukasa Kusakabe, Kyo Kutsuzawa, Sho Sakaino, and Toshiaki Tsuji, &ldquo;Reinforcement Learning for Robotic Assembly Using Non-Diagonal Stiffness Matrix,&rdquo; IEEE Robotics and Automation Letters, vol. 6, no. 2, pp. 2737–2744, 2021. DOI: <a href="https://doi.org/10.1109/LRA.2021.3060389">10.1109/LRA.2021.3060389</a></li>
                    <li>Kyo Kutsuzawa, Sho Sakaino, and Toshiaki Tsuji, &ldquo;Simultaneous Estimation of Contact Position and Tool Shape using Unscented Particle Filter,&rdquo; IEEJ Journal of Industry Applications, vol. 9, no. 5, pp. 505–514, 2020. DOI: <a href="https://doi.org/10.1541/ieejjia.9.505">10.1541/ieejjia.9.505</a> (Open Access)</li>
                    <li>Daichi Furuta, Kyo Kutsuzawa, Sho Sakaino, and Toshiaki Tsuji, &ldquo;Motion Planning with Success Judgement Model based on Learning from Demonstration,&rdquo; IEEE Access, vol. 8, pp. 73142–73150, 2020.  DOI: <a href="https://doi.org/10.1109/ACCESS.2020.2987604">10.1109/ACCESS.2020.2987604</a> (Open Access)<br>Corresponding author: Kyo Kutsuzawa</li>
                    <li>Kyo Kutsuzawa, Sho Sakaino, and Toshiaki Tsuji, &ldquo;Trajectory adjustment for nonprehensile manipulation using latent space of trained sequence-to-sequence model,&rdquo; Advanced Robotics, vol. 33, no. 21, pp. 1144–1154, 2019. DOI: <a href="https://doi.org/10.1080/01691864.2019.1673204">10.1080/01691864.2019.1673204</a><br>Postprint Available: <a href="https://kyo-kutsuzawa.github.io/ar2019/">https://kyo-kutsuzawa.github.io/ar2019/</a><br><em>Advanced Robotics Excellent Paper Award</em></li>
                    <li>Kyo Kutsuzawa, Sho Sakaino, and Toshiaki Tsuji, &ldquo;Sequence-to-Sequence Model for Trajectory Planning of Nonprehensile Manipulation Including Contact Model,&rdquo; IEEE Robotics and Automation Letters, vol. 3, no. 4, pp. 3606–3613, 2018. DOI: <a href="https://doi.org/10.1109/LRA.2018.2854958">10.1109/LRA.2018.2854958</a> (Open Access)</li>
                    <li>Toshiaki Tsuji, Kyo Kutsuzawa, and Sho Sakaino, &ldquo;Optimized Trajectory Generation based on Model Predictive Control for Turning Over Pancakes,&rdquo; IEEJ Journal of Industry Applications, vol. 7, no. 1, pp. 22–28, 2018. DOI: <a href="https://doi.org/10.1541/ieejjia.7.22">10.1541/ieejjia.7.22</a> (Open Access)</li>
                    <li>Toshiaki Tsuji, Kyo Kutsuzawa, and Sho Sakaino, &ldquo;Acceleration Control for Dynamic Manipulation of a Robot Turning Over Objects,&rdquo; IEEE Robotics and Automation Letters, vol. 2, no. 4, pp. 2328–2335, 2017. DOI: <a href="https://doi.org/10.1109/LRA.2017.2720848">10.1109/LRA.2017.2720848</a></li>
                    <li>Kyo Kutsuzawa, Sho Sakaino, and Toshiaki Tsuji, &ldquo;A Control System for a Tool Use Robot: Drawing a Circle by Educing Functions of a Compass,&rdquo; Journal of Robotics and Mechatronics, vol. 29, no. 2, pp. 395–405, 2017. DOI: <a href="https://doi.org/10.20965/jrm.2017.p0395">10.20965/jrm.2017.p0395</a> (Open Access)</li>
                </ol>
            </section>

            <section>
                <h2>International Conferences (peer-reviewed)</h2>

                <ol>
                    <li>Moeko Kojima, Kyo Kutsuzawa, Dai Owaki, and Mitsuhiro Hayashibe, &ldquo;Game-Based Evaluation of Whole-Body Movement Functions with CoM Stability and Motion Smoothness,&rdquo; the 44th Annual International Conference of the IEEE Engineering in Medicine and Biology Society (EMBC 2022), 2022, pp. 4354–4357. DOI: <a href="https://doi.org/10.1109/EMBC48229.2022.9870892">10.1109/EMBC48229.2022.9870892</a></li>
                    <li>Kenya Tada, Kyo Kutsuzawa, Dai Owaki, and Mitsuhiro Hayashibe, &ldquo;Quantifying Motor and Cognitive Function of the Upper Limb Using Mixed Reality Smartglasses,&rdquo; the 44th Annual International Conference of the IEEE Engineering in Medicine and Biology Society (EMBC 2022), 2022, pp. 2556–2559. DOI: <a href="https://doi.org/10.1109/EMBC48229.2022.9871648">10.1109/EMBC48229.2022.9871648</a></li>
                    <li>Kazuki Furuhata, Kyo Kutsuzawa, Dai Owaki, and Mitsuhiro Hayashibe, &ldquo;Systematic Motion Integration with Multiple Depth Cameras Allowing Sensor Movement for Stable Skeleton Tracking,&rdquo; the 44th Annual International Conference of the IEEE Engineering in Medicine and Biology Society (EMBC 2022), 2022, pp. 1801–1804. DOI: <a href="https://doi.org/10.1109/EMBC48229.2022.9870876">10.1109/EMBC48229.2022.9870876</a></li>
                    <li>Kyo Kutsuzawa and Mitsuhiro Hayashibe, &ldquo;A Geometric Design Method for Variable Impedance Parameters in Assembly Tasks,&rdquo; the 8th IEEJ International Workshop on Sensing, Actuation, Motion Control, and Optimization (SAMCON 2022), 2022.</li>
                    <li>Masahide Oikawa, Kyo Kutsuzawa, Sho Sakaino, and Toshiaki Tsuji, &ldquo;Admittance Control Based on a Stiffness Ellipse for Rapid Trajectory Deformation,&rdquo; the 16th International Workshop on Advanced Motion Control (AMC 2020), 2020, pp. 23–28. DOI: <a href="https://doi.org/10.1109/AMC44022.2020.9244385">10.1109/AMC44022.2020.9244385</a></li>
                    <li>Kyo Kutsuzawa, Sho Sakaino, and Toshiaki Tsuji, &ldquo;Simultaneous Estimation of Contact Position and Tool Shape using Particle Filter,&rdquo; the 5th IEEJ International Workshop on Sensing, Actuation, Motion Control, and Optimization (SAMCON 2019), 2019.<br><em>IEEJ Industrial Application Society Excellent Presentation Award</em></li>
                    <li>Kyo Kutsuzawa, Sho Sakaino, and Toshiaki Tsuji, &ldquo;Sequence-to-Sequence Model for Trajectory Planning of Nonprehensile Manipulation Including Contact Model,&rdquo; the 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS 2018), 2018, pp. 3648–3653. DOI: <a href="https://doi.org/10.1109/LRA.2018.2854958">10.1109/LRA.2018.2854958</a> (Open Access)</li>
                    <li>Daichi Furuta, Kyo Kutsuzawa, Sho Sakaino, and Toshiaki Tsuji, &ldquo;LSTM learning of inverse dynamics with contact in various environments,&rdquo; the 12th France-Japan and 10th Europe-Asia Congress on Mechatronics, 2018, pp. 149–154. DOI: <a href="https://doi.org/10.1109/MECATRONICS.2018.8495698">10.1109/MECATRONICS.2018.8495698</a></li>
                    <li>Kyo Kutsuzawa, Sho Sakaino, and Toshiaki Tsuji, &ldquo;Deformation of Contact Motion by Neural Networks to Adapt for Various Environment Change,&rdquo; the 4th IEEJ International Workshop on Sensing, Actuation, Motion Control, and Optimization (SAMCON 2018), 2018.</li>
                    <li>Tetsugaku Okamoto, Kyo Kutsuzawa, Sho Sakaino, and Toshiaki Tsuji, &ldquo;Trajectory Planning by Variable Length Chunk of Sequence-to-Sequence Using Hierarchical Decoder,&rdquo; the 15th International Workshop on Advanced Motion Control (AMC 2018), 2018, pp. 209–214. DOI: <a href="https://doi.org/10.1109/AMC.2019.8371089">10.1109/AMC.2019.8371089</a></li>
                    <li>Kyo Kutsuzawa, Sho Sakaino, and Toshiaki Tsuji, &ldquo;Sequence-to-Sequence Models for Trajectory Deformation of Dynamic Manipulation,&rdquo; the 43rd Annual Conference of the IEEE Industrial Electronics Society (IECON 2017), 2017, pp. 5227–5232. DOI: <a href="https://doi.org/10.1109/IECON.2017.8216904">10.1109/IECON.2017.8216904</a></li>
                    <li>Daichi Furuta, Kyo Kutsuzawa, Sho Sakaino, and Toshiaki Tsuji, &ldquo;Model Predictive Control based Deep Neural Network for Dynamic Manipulation,&rdquo; the 43rd Annual Conference of the IEEE Industrial Electronics Society (IECON 2017), 2017, pp. 5215–5220. DOI: <a href="https://doi.org/10.1109/IECON.2017.8216902">10.1109/IECON.2017.8216902</a></li>
                    <li>Kyo Kutsuzawa, Sho Sakaino, and Toshiaki Tsuji, &ldquo;Learning identity mapping of trajectories by sequence-to-sequence model with time series chunking,&rdquo; the 3rd IEEJ International Workshop on Sensing, Actuation, Motion Control, and Optimization (SAMCON 2017), 2017.</li>
                    <li>Kyo Kutsuzawa, Sho Sakaino, and Toshiaki Tsuji, &ldquo;Estimation of individual force at three contact points on an end-effector by a six-axis force torque sensor,&rdquo; the 42nd Annual Conference of IEEE Industrial Electronics Society (IECON 2016), 2016, pp. 6409–6414. DOI: <a href="https://doi.org/10.1109/IECON.2016.7793932">10.1109/IECON.2016.7793932</a><br><em>IES Student Paper Travel Assistance</em></li>
                    <li>Tetsugaku Okamoto, Kyo Kutsuzawa, Sho Sakaino, and Toshiaki Tsuji, &ldquo;Trajectory Planning Method for Object Manipulation Considering Dynamic Constraint with Object,&rdquo; the 2016 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS 2016), 2016. (Workshop)</li>
                    <li>Kyo Kutsuzawa, Sho Sakaino, and Toshiaki Tsuji, &ldquo;Estimation of Individual Contact Force when Two Contact Points Exist during Robotic Tool Use,&rdquo; the 6th International Conference on Advanced Mechatronics (ICAM 2015), 2015, 1A1-24. DOI: <a href="https://doi.org/10.1299/jsmeicam.2015.6.46">10.1299/jsmeicam.2015.6.46</a> (Open Access)</li>
                </ol>
            </section>

            <section>
                <h2>International Conferences (no peer-reviewed)</h2>

                <ol>
                    <li>Kyo Kutsuzawa, Sho Sakaino, and Toshiaki Tsuji, &ldquo;Simultaneous Estimation of Contact Position and Tool Shape using Unscented Particle Filter,&rdquo; the 6th IEEJ International Workshop on Sensing, Actuation, Motion Control, and Optimization (SAMCON 2020), 2020. (JIA-to-SAMCON option)<br><em>IEEJ Industrial Application Society Excellent Presentation Award</em></li>
                    <li>Kyo Kutsuzawa, Sho Sakaino, and Toshiaki Tsuji, &ldquo;Contact Force Estimation for Multiple Points of Contact,&rdquo; the 2016 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS 2016), 2016. (Late breaking presentation)</li>
                </ol>
            </section>

            <section>
                <h2>Domestic Conferences (no peer-reviewed)</h2>

                <ol>
                    <li>平野貴也, 沓澤京, 大脇大, 林部充宏; &ldquo;時定数と膜抵抗の動的変動による広範な時間スケールに頑健なSpiking Neural Networkの構築,&rdquo; 第25回計測自動制御学会システムインテグレーション部門講演会, 2024, 3G2-07.</li>
                    <li>反町優平, 沓澤京, 大脇大, 林部充宏; &ldquo;Mixed Realityを用いた物体把持操作におけるシナジー抽出を介した手指運動機能評価,&rdquo; 第25回計測自動制御学会システムインテグレーション部門講演会, 2024, 2A4-04.</li>
                    <li>田中裕人, 沓澤京, 大脇大, 林部充宏; &ldquo;シナジーに基づく報酬推定による模倣学習のオフライン強化学習への拡張,&rdquo; 第25回計測自動制御学会システムインテグレーション部門講演会, 2024, 1E5-04.</li>
                    <li>瀬戸崚生, 沓澤京, 大脇大, 林部充宏; &ldquo;四脚ロボットの姿勢反射学習によるCPG-RLの不整地における歩行性能の向上,&rdquo; 第25回計測自動制御学会システムインテグレーション部門講演会, 2024, 1E5-01.</li>
                    <li>田中裕人, 沓澤京, ⼤脇⼤, 林部充宏: &ldquo;シナジーを利用した低品質な教示動作を含むデータセットからの模倣学習,&rdquo; 計測自動制御学会 東北支部 第348回研究集会, 2024, 348-2.<br><em>計測自動制御学会東北支部優秀発表奨励賞 受賞</em><br>Open Access: <a href="https://www.topic.ad.jp/sice/htdocs/papers/348/348-2.pdf">https://www.topic.ad.jp/sice/htdocs/papers/348/348-2.pdf</a></li>
                    <li>北原寛, 沓澤京, 大脇大, 林部充宏, &ldquo;異なる速度の歩行運動における筋シナジーと運動シナジー間の関連性,&rdquo; ロボティクス・メカトロニクス講演会2024, 2024, 1P2-I08.</li>
                    <li>日野衆斗, 沓澤京, 大脇大, 林部充宏, &ldquo;触覚を介した物理的相互作用によるステアリング操作運動の学習速度向上,&rdquo; ロボティクス・メカトロニクス講演会2024, 2024, 1P1-G02.</li>
                    <li>後藤啓佑, 沓澤京, 大脇大, 林部充宏, &ldquo;SSVEPとMotor Imageryを用いたハイブリッドBCIの制御向上,&rdquo; ロボティクス・メカトロニクス講演会2024, 2024, 1A1-Q07.</li>
                    <li>北原寛, 沓澤京, ⼤脇⼤, 林部充宏: &ldquo;シナジーに基づく異なる速度の歩行運動における筋活動と運動の関連性の分析,&rdquo; 計測自動制御学会 東北支部 第347回研究集会, 2024, 347-3.<br><em>計測自動制御学会東北支部優秀発表奨励賞 受賞</em><br>Open Access: <a href="https://www.topic.ad.jp/sice/htdocs/papers/347/347-3.pdf">https://www.topic.ad.jp/sice/htdocs/papers/347/347-3.pdf</a></li>
                    <li>赤井田祐樹, 沓澤京, 大脇大, 林部充宏: &ldquo;仮想物体の把持操作におけるシナジー成分分析に基づく手指運動機能の評価,&rdquo; 第36回自律分散システム・シンポジウム, 2024, 1A1-4.<br><em>萌芽研究部門 優秀研究奨励賞</em></li>
                    <li>轟将吾, 沓澤京, 大脇大, 林部充宏: &ldquo;BCI における分類可能クラス数の増加を目的とした運動速度イメージの解読,&rdquo; 第24回計測自動制御学会システムインテグレーション部門講演会, 2023, 3E2-13.<br><em>SI2023 優秀講演賞 受賞</em></li>
                    <li>松本実南, 沓澤京, 大脇大, 林部充宏: &ldquo;多指ハンドの把持におけるニューラルネットワークを用いた対象物の物理的特性の推定,&rdquo; 第24回計測自動制御学会システムインテグレーション部門講演会, 2023, 2C2-05.<br><em>SI2023 優秀講演賞 受賞</em></li>
                    <li>松村拓海, 沓澤京, 大脇大, 林部充宏: &ldquo;time-varying シナジーを用いた異なる速度の歩行運動の時空間的解析,&rdquo; 第24回計測自動制御学会システムインテグレーション部門講演会, 2023, 2D1-01.</li>
                    <li>赤井田祐樹, 沓澤京, 大脇大, 林部充宏: &ldquo;手指機能評価のための仮想物体の把持操作におけるシナジー解析,&rdquo; 第24回計測自動制御学会システムインテグレーション部門講演会, 2023, 1A5-07.</li>
                    <li>利根川太, 沓澤京, 大脇大, 林部充宏: &ldquo;二輪脚倒立振子型ロボットにおける膝関節制御の導入による不整地走破性および安定性の向上,&rdquo; 第24回計測自動制御学会システムインテグレーション部門講演会, 2023, 1B1-01.</li>
                    <li>平野貴也, 沓澤京, 大脇大, 林部充宏: &ldquo;スパイク形式による画像の潜在表現を用いたモデルベース強化学習の性能評価,&rdquo; 計測自動制御学会 東北支部 第344回研究集会, 2023, 344-2.<br><em>計測自動制御学会東北支部優秀発表奨励賞 受賞</em><br>Open Access: <a href="https://www.topic.ad.jp/sice/htdocs/papers/344/344-2.pdf">https://www.topic.ad.jp/sice/htdocs/papers/344/344-2.pdf</a></li>
                    <li>沓澤京, 林部充宏: &ldquo;時変シナジーを利用したドア開けタスクの模倣学習,&rdquo; 第41回日本ロボット学会学術講演会, 2022, 3K2-03.</li>
                    <li>瀬戸崚生, 沓澤京, 大脇大, 林部充宏: &ldquo;スパイク表現を用いた深層強化学習による四脚ロボットの歩容生成,&rdquo; ロボティクス・メカトロニクス講演会2023, 2023, 2P1-G09.</li>
                    <li>平野貴也, 沓澤京, 大脇大, 林部充宏: &ldquo;スパイク形式による画像の潜在表現を用いたモデルベース強化学習の性能評価,&rdquo; ロボティクス・メカトロニクス講演会2023, 2023, 1P1-G10.</li>
                    <li>田中裕人, 沓澤京, 大脇大, 林部充宏: &ldquo;機械学習を用いた物理振子群の同期ダイナミクス予測,&rdquo; ロボティクス・メカトロニクス講演会2023, 2023, 1A2-F27.</li>
                    <li>反町優平, 沓澤京, 大脇大, 林部充宏: &ldquo;複数台の深度カメラを用いた身体バランス評価を目的とした複合現実ウェアラブルゲームの開発,&rdquo; ロボティクス・メカトロニクス講演会2023, 2023, 1A1-D24.</li>
                    <li>沓澤京, 林部充宏: &ldquo;力覚信号に基づく粒子フィルタを用いた多数のパラメータで表現される道具形状の推定,&rdquo; 計測自動制御学会 東北支部 第342回研究集会, 2023, 342-4.<br><em>計測自動制御学会東北支部優秀発表奨励賞 受賞</em><br>Open Access: <a href="https://www.topic.ad.jp/sice/htdocs/papers/342/342-4.pdf">https://www.topic.ad.jp/sice/htdocs/papers/342/342-4.pdf</a></li>
                    <li>反町優平, 沓澤京, 大脇大, 林部充宏: &ldquo;複数台深度カメラを用いた複合現実ウェアラブルゲームによる身体バランス評価,&rdquo; 計測自動制御学会 東北支部 第342回研究集会, 2023, 342-3.<br>Open Access: <a href="https://www.topic.ad.jp/sice/htdocs/papers/342/342-3.pdf">https://www.topic.ad.jp/sice/htdocs/papers/342/342-3.pdf</a></li>
                    <li>田中裕人, 沓澤京, 大脇大, 林部充宏: &ldquo;機械学習を用いた物理振子群における同期現象の予測と評価,&rdquo; 計測自動制御学会 東北支部 第341回研究集会, 2023, 341-4.<br>Open Access: <a href="https://www.topic.ad.jp/sice/htdocs/papers/341/341-4.pdf">https://www.topic.ad.jp/sice/htdocs/papers/341/341-4.pdf</a></li>
                    <li>瀬戸崚生, 沓澤京, 大脇大, 林部充宏: &ldquo;スパイク表現を用いた深層強化学習により生成された四脚ロボットの歩容評価,&rdquo; 計測自動制御学会 東北支部 第341回研究集会, 2023, 341-2.<br>Open Access: <a href="https://www.topic.ad.jp/sice/htdocs/papers/341/341-2.pdf">https://www.topic.ad.jp/sice/htdocs/papers/341/341-2.pdf</a></li>
                    <li>吉田高志, 沓澤京, 大脇大, 林部充宏: &ldquo;モデルベース強化学習により生成された速度の異なる歩行運動パターンに共通するシナジー発現特性の検証,&rdquo; 第23回計測自動制御学会システムインテグレーション部門講演会, 2022, 3P2-F04.<br><em>SI2022 優秀講演賞 受賞</em></li>
                    <li>平井虎太朗, 沓澤京, 大脇大, 林部充宏: &ldquo;モデルベース強化学習を用いたヘビ型ロボットの環境適応性に関する実験的検証,&rdquo; 第23回計測自動制御学会システムインテグレーション部門講演会, 2022, 1P2-F01.<br><em>SI2022 優秀講演賞 受賞</em></li>
                    <li>多田憲矢, 沓澤京, 大脇大, 林部充宏: &ldquo;Mixed Reality デバイスを用いた動的リーチングタスクによる認知機能と運動機能の定量化,&rdquo; 第23回計測自動制御学会システムインテグレーション部門講演会, 2022, 1P2-D15.</li>
                    <li>瀬宮優作, 沓澤京, 大脇大, 林部充宏: &ldquo;脚ロボットにおける複数の歩行パターンの模倣に基づく遷移動作の学習,&rdquo; 第23回計測自動制御学会システムインテグレーション部門講演会, 2022, 1P2-D07.<br><em>SI2022 優秀講演賞 受賞</em></li>
                    <li>古関駿介, 沓澤京, 大脇大, 林部充宏: &ldquo;深層強化学習により獲得される二脚歩容遷移にみられるヒステリシス現象,&rdquo; 計測自動制御学会 東北支部 第339回研究集会, 2022, 339-7.<br><em>計測自動制御学会東北支部優秀発表奨励賞 受賞</em><br>Open Access: <a href="https://www.topic.ad.jp/sice/htdocs/papers/339/339-7.pdf">https://www.topic.ad.jp/sice/htdocs/papers/339/339-7.pdf</a></li>
                    <li>下村尚道, 沓澤京, 林部充宏: &ldquo;ビジョンシステムを用いた非均一な形状の平面物体の認識に関する研究,&rdquo; 計測自動制御学会 東北支部 第338回研究集会, 2022, 338-1.<br>Open Access: <a href="https://www.topic.ad.jp/sice/htdocs/papers/338/338-1.pdf">https://www.topic.ad.jp/sice/htdocs/papers/338/338-1.pdf</a></li>
                    <li>古関駿介, 沓澤京, 大脇大, 林部充宏: &ldquo;深層強化学習を用いた二脚モデルにおける歩容遷移の実現,&rdquo; 第40回日本ロボット学会学術講演会, 2022, 2E3-03.</li>
                    <li>沓澤京, 林部充宏: &ldquo;Time-varying synergyを用いた動作の時空間的構造抽出による模倣学習,&rdquo; 第40回日本ロボット学会学術講演会, 2022, 2K3-01.</li>
                    <li>福西彬仁, 沓澤京, ⼤脇⼤, 林部充宏: &ldquo;筋骨格モデルにおけるモジュールを用いた異なる姿勢への適応能力の効果,&rdquo; 計測自動制御学会 東北支部 第337回研究集会, 2022, 337-8.<br><em>計測自動制御学会東北支部優秀発表奨励賞 受賞</em><br>Open Access: <a href="https://www.topic.ad.jp/sice/htdocs/papers/337/337-8.pdf">https://www.topic.ad.jp/sice/htdocs/papers/337/337-8.pdf</a></li>
                    <li>多田憲矢, 沓澤京, ⼤脇⼤, 林部充宏: &ldquo;Mixed Realityデバイスを用いた上肢の運動機能と認知機能の定量化に関する研究,&rdquo; 計測自動制御学会 東北支部 第337回研究集会, 2022, 337-2.<br><em>計測自動制御学会東北支部優秀発表奨励賞 受賞</em><br>Open Access: <a href="https://www.topic.ad.jp/sice/htdocs/papers/337/337-2.pdf">https://www.topic.ad.jp/sice/htdocs/papers/337/337-2.pdf</a></li>
                    <li>杉山拓, 沓澤京, 大脇大, 林部充宏: &ldquo;空圧/水圧両用駆動に向けたBending-type Fluidic Elastomer Actuatorの動作特性評価,&rdquo; ロボティクス・メカトロニクス講演会2022, 2022, K05-2P1.</li>
                    <li>平井虎太朗, 沓澤京, 大脇大, 林部充宏: &ldquo;モデルベース強化学習を用いたヘビ型ロボットの環境適応性検証,&rdquo; ロボティクス・メカトロニクス講演会2022, 2022, P04-2A2.</li>
                    <li>松村拓海, 沓澤京, 大脇大, 林部充宏: &ldquo;歩行運動の速度と負荷変化に対する時空間筋シナジー解析,&rdquo; ロボティクス・メカトロニクス講演会2022, 2022, I09-2A1.</li>
                    <li>赤井田祐樹, 沓澤京, 大脇大, 林部充宏: &ldquo;再帰型ニューラルネットワークによる手指運動の即時判別と後だしじゃんけんを用いた認知課題の定量化,&rdquo; ロボティクス・メカトロニクス講演会2022, 2022, A10-2A1.</li>
                    <li>小嶋萌子, 沓澤京, 大脇大, 林部充宏: &ldquo;ゲーム環境下における重心情報を用いた運動機能の多角的評価,&rdquo; 第22回計測自動制御学会システムインテグレーション部門講演会, 2021, 3E4-02.</li>
                    <li>高柳峻也, 沓澤京, 大脇大, 林部充宏: &ldquo;時系列解析手法を用いた結合振動子系の同期ダイナミクス予測の評価,&rdquo; 第22回計測自動制御学会システムインテグレーション部門講演会, 2021, 2F5-03.</li>
                    <li>古畑和樹, 沓澤京, 大脇大, 林部充宏: &ldquo;センサの移動を許容する複数深度カメラの人体骨格モデルの運動情報統合,&rdquo; 第22回計測自動制御学会システムインテグレーション部門講演会, 2021, 2B2-09.</li>
                    <li>納谷克海, 沓澤京, 大脇大, 林部充宏: &ldquo;スパイキングニューラルネットワークに基づく深層強化学習による脚ロボットの歩行生成と耐故障性評価,&rdquo; 第22回計測自動制御学会システムインテグレーション部門講演会, 2021, 1C5-02.<br><em>SI2021 優秀講演賞 受賞</em></li>
                    <li>古関駿介, 沓澤京, ⼤脇⼤, 林部充宏: &ldquo;深層強化学習を⽤いた準受動歩⾏および⾛⾏の実現,&rdquo; 計測自動制御学会 東北支部 第334回研究集会, 2021, 334-2.<br>Open Access: <a href="https://www.topic.ad.jp/sice/htdocs/papers/334/334-2.pdf">https://www.topic.ad.jp/sice/htdocs/papers/334/334-2.pdf</a></li>
                    <li>納谷克海, 沓澤京, 大脇大, 林部充宏: &ldquo;スパイキングニューラルネットワークに基づく深層強化学習による脚ロボットの歩行生成と評価,&rdquo; 計測自動制御学会 東北支部 第332回研究集会, 2021, 332-1.<br><em>計測自動制御学会東北支部優秀発表奨励賞 受賞</em><br>Open Access: <a href="https://www.topic.ad.jp/sice/htdocs/papers/332/332-1.pdf">https://www.topic.ad.jp/sice/htdocs/papers/332/332-1.pdf</a></li>
                    <li>福西彬仁, 沓澤京, 大脇大, 林部充宏: &ldquo;筋骨格モデルを用いた運動学習におけるモジュラリティの役割検証,&rdquo; ロボティクス・メカトロニクス講演会2021, 2021, 2P3-E06.</li>
                    <li>吉田高志, Jiazheng Chai, 沓澤京, 大脇大, 林部充宏: &ldquo;モデルベース強化学習により獲得される歩行運動に内在する脚協調構造,&rdquo; ロボティクス・メカトロニクス講演会2021, 2021, 1P3-E04.</li>
                    <li>平井虎太朗, 沓澤京, 大脇大, 林部充宏: &ldquo;モデルベース強化学習を用いたヘビ型ロボットの実験的検証,&rdquo; ロボティクス・メカトロニクス講演会2021, 2021, 1P1-I10.</li>
                    <li>瀬宮優作, 沓澤京, 大脇大, 林部充宏: &ldquo;エンコーダ-デコーダモデルによる脚ロボットの歩行動作生成,&rdquo; ロボティクス・メカトロニクス講演会2021, 2021, 1P1-I07.</li>
                    <li>杉山拓, 沓澤京, 大脇大, 林部充宏: &ldquo;ニューラルネットワークによる水圧駆動型ソフトアクチュエータの汎化軌道追従制御,&rdquo; 計測自動制御学会 東北支部 第331回研究集会, 2021, 331-5.<br><em>計測自動制御学会東北支部優秀発表奨励賞 受賞</em><br>Open Access: <a href="https://www.topic.ad.jp/sice/htdocs/papers/331/331-5.pdf">https://www.topic.ad.jp/sice/htdocs/papers/331/331-5.pdf</a></li>
                    <li>清水寛子, 沓澤京, 大脇大, 林部充宏: &ldquo;深層強化学習を用いたばね付き準受動歩行モデルにおける歩容生成,&rdquo; 第21回計測自動制御学会システムインテグレーション部門講演会, 2020, 1D3-02.<br><em>SI2020 優秀講演賞 受賞</em></li>
                    <li>岩熊孝幸, 多和田昇平, 内田智啓, 沓澤京, 野村泰朗, 渡邊彩夏, 奥川雅之, 土井智晴: &ldquo;レスコンシーズにおける個人活動を集団活動に繋げる取り組み,&rdquo; 第21回計測自動制御学会システムインテグレーション部門講演会, 2020, 1A2-04.</li>
                    <li>猪股映史, Felipe M. Ramos, 沓澤京, 大脇大, 林部充宏: &ldquo;サイクリング運動の速度・負荷変化に対する筋シナジー適応解析,&rdquo; 第38回日本ロボット学会学術講演会, 2020, 2H3-01.</li>
                    <li>杉山拓, 沓澤京, 大脇大, 林部充宏: &ldquo;反復学習制御によるFiber-Reinforced Soft Actuatorの個体差補償,&rdquo; 第38回日本ロボット学会学術講演会, 2020, 2A2-02.</li>
                    <li>沓澤京, 境野翔, 辻俊明: &ldquo;画像情報を含んだ模倣学習におけるSequence-to-Sequence Autoencoderの利用,&rdquo; 第37回日本ロボット学会学術講演会, 2019, 1A3-08.</li>
                    <li>沓澤京, 草野仁志, 久米絢佳, 山口正一朗: &ldquo;Conditional Generative Adversarial Networksによる環境状況を考慮した投擲動作の生成,&rdquo; 第37回日本ロボット学会学術講演会, 2019, 1A2-04.</li>
                    <li>及川 将秀, 沓澤京, 境野翔, 辻俊明: &ldquo;組み立て作業のための力制御における剛性楕円の自律生成,&rdquo; 第37回日本ロボット学会学術講演会, 2019, 1A1-07.</li>
                    <li>佐藤航陽, 及川将秀, 古田大地, 沓澤京, 境野翔, 辻俊明: &ldquo;ニューラルネットワークを用いたペンのはめ合いタスクにおける力情報による成否判定,&rdquo; ロボティクス・メカトロニクス講演会2019, 2019, 2P1-R04.</li>
                    <li>植木俊宏, 沓澤京, 及川将秀, 辻俊明, 境野翔: &ldquo;力制御の特性を活用した Peg-in-Hole における軌道計画法の提案,&rdquo; ロボティクス・メカトロニクス講演会2019, 2019, 2A2-C16.</li>
                    <li>沓澤京, 境野翔, 辻俊明: &ldquo;訓練済み軌道生成モデルを用いた新たな動作目標への軌道最適化,&rdquo; 第36回日本ロボット学会学術講演会, 2018, 2E2-06.</li>
                    <li>小西祐也, 沓澤京, 境野翔, 辻俊明: &ldquo;力のアクティブセンシングに基づく道具の形状推定,&rdquo; ロボティクス・メカトロニクス講演会2018, 2018, 2A1-G15.</li>
                    <li>沓澤京, 戸津信寛, 境野翔, 辻俊明: &ldquo;拡張現実感を利用した力可視化による作業支援システム&rdquo; 第18回計測自動制御学会システム・インテグレーション部門講演会, 2017, 1B5-05.</li>
                    <li>沓澤京, 境野翔, 辻俊明: &ldquo;sequence-to-sequenceモデルを用いた軌道生成における外乱補償能力の検証,&rdquo; 第35回日本ロボット学会学術講演会, 2017, 1I3-02.<br><em>日本ロボット学会研究奨励賞 受賞</em></li>
                    <li>古田大地, 沓澤京, 岡本哲学, 境野翔, 辻俊明: &ldquo;動力学拘束を考慮したモデル予測制御のディープニューラルネットワーク学習,&rdquo; ロボティクス・メカトロニクス講演会2017, 2017, 1P10-I12.</li>
                    <li>岡本哲学, 沓澤京, 辻俊明: &ldquo;RRTによる物体との動力学的な拘束を考慮した物体操作の軌道生成アルゴリズム,&rdquo; ロボティクス・メカトロニクス講演会2016, 2016, 2P2-08b6.</li>
                    <li>清水康平, 沓澤京, 辻俊明: &ldquo;モデル予測制御による環境との接触を考慮したロボットの最適動作計画,&rdquo; ロボティクス・メカトロニクス講演会2016, 2016, 2P1-03b5.</li>
                    <li>沓澤京, 大熊隼, 境野翔, 辻俊明: &ldquo;コンパスで円を描く動作を実現する制御,&rdquo; ロボティクス・メカトロニクス講演会2015, 2015, 2P1-F07.</li>
                    <li>沓澤京, 岩熊孝幸, 野村泰朗: &ldquo;埼玉における学生主体のレスコンシーズ活動の展開と課題,&rdquo; 第15回計測自動制御学会システムインテグレーション部門講演会, 2014, 2A3-6.</li>
                </ol>
            </section>

            <section>
                <h2>Misc. (no peer-reviewed)</h2>

                <ol>
                    <li>沓澤京, &ldquo;Shared Synergyを利用した高い汎化能力をもたらす模倣学習,&rdquo; 日本ロボット学会誌, vol. 41, no. 8, pp. 661–664, 2023. （解説記事）</li>
                    <li>Masahide Oikawa, Kyo Kutsuzawa, Sho Sakaino, and Toshiaki Tsuji, &ldquo;Assembly robots with optimized control stiffness through reinforcement learning,&rdquo; arXiv preprint arXiv:2002.12207, 2020. DOI: <a href="https://doi.org/10.48550/arXiv.2002.12207">10.48550/arXiv.2002.12207</a></li>
                    <li>Kyo Kutsuzawa, Hitoshi Kusano, Ayaka Kume, Shoichiro Yamaguchi, &ldquo;Motion Generation Considering Situation with Conditional Generative Adversarial Networks for Throwing Robots,&rdquo; arXiv preprint arXiv:1910.03253, 2019. DOI: <a href="https://doi.org/10.48550/arXiv.1910.03253">10.48550/arXiv.1910.03253</a></li>
                </ol>
            </section>
        </section>

        <section id="achievements">
            <h1>Achievements</h1>

            <section>
                <h2>Awards</h2>

                <ol>
                    <li>産業応用部門　論文査読促進賞, 一般社団法人電気学会産業応用部門, 2023-08-22.<br>(IEEJ Industry Applications Society Quick Paper Review Promotion Award, IEEJ Industry Applications Society)<br><a href="https://www.iee.jp/ias/about/award/industry2023/">Web page</a></li>
                    <li>計測自動制御学会東北支部優秀発表奨励賞, 計測自動制御学会東北支部, 2023-05-26.<br>(Tohoku Chapter Incentive Award, The Society of Instrument and Control Engineers Tohoku Chapter)<br><a href="https://www.topic.ad.jp/sice/htdocs/2023/awardevents.html">Web page</a>, <a href="https://www.topic.ad.jp/sice/htdocs/papers/342/342-4.pdf">Paper</a></li>
                    <li>IEEJ Industry Applications Society Excellent Presentation Award, IEEJ Industry Applications Society, 2021-08-26.<br><a href="https://www.jstage.jst.go.jp/article/ieejias/141/9/141_NL9_12/_article/-char/ja">Web page</a>, <a href="https://doi.org/10.1541/ieejjia.9.505">Paper</a></li>
                    <li>Advanced Robotics Excellent Paper Award, The Robotics Society of Japan, 2020-10-09.<br><a href="https://robogaku.jp/news/2020/award2020/arpa_epa02.html">Web page</a>, <a href="https://www.tandfonline.com/doi/full/10.1080/01691864.2019.1673204">Paper</a>, <a href="https://kyo-kutsuzawa.github.io/ar2019/">Postprint</a></li>
                    <li>IEEJ Industry Applications Society Excellent Presentation Award, IEEJ Industry Applications Society, 2019-08-20.<br><a href="https://www.jstage.jst.go.jp/article/ieejias/139/9/139_NL9_8/_article/-char/ja">Web page</a></li>
                    <li>日本ロボット学会研究奨励賞, 日本ロボット学会, 2018-09-06.<br>(Young Investigator Excellence Award, The Robotics Society of Japan)<br><a href="https://www.rsj.or.jp/info/awards/category/investigation/">Web page</a></li>
                    <li>埼玉大学学生表彰, 埼玉大学, 2017-03-08.<br>(Saitama University Student Award, Saitama University)<br><a href="http://www.saitama-u.ac.jp/news_archives/2017-0310-1202-9.html">Web page</a></li>
                    <li>IES Student Paper Travel Assistance, IEEE Industrial Electronics Society, 2016-10-24.<br>(with payment up to USD 2000 as a support to attend the conference)<br><a href="https://ieeexplore.ieee.org/document/7884001">Web page</a>, <a href="https://ieeexplore.ieee.org/abstract/document/7793932">Proceeding</a>, <a href="https://www.youtube.com/watch?v=Dtp8delmLwM">Video</a></li>
                    <li>電気学会東京支部学術奨励賞, 電気学会東京支部, 2015-03-31.<br>(IEEJ Tokyo Branch Student Encouragement Award, The Institute of Electrical Engineers of Japan Tokyo Branch)<br><a href="https://www.iee.jp/tokyo/award/encourage/h26/">Web page</a></li>
                </ol>
            </section>

            <section>
                <h2>Invited Talks</h2>

                <ol>
                    <li>&ldquo;ロボットの運動制御における深層学習の応用,&rdquo; トライボロジー会議2024 春 東京, 2024-05-27.<br>URL <a href="https://www.tribology.jp/conference/tribology_conference/24tokyo/">https://www.tribology.jp/conference/tribology_conference/24tokyo/</a></li>
                    <li>&ldquo;シナジーを利用した模倣学習,&rdquo; 2023年電気学会産業応用部門大会, 2-S2-4, 2023-08-22.<br>URL <a href="https://pdf.gakkai-web.net/jiasc/program/hp23/doc/program_symposium.pdf">https://pdf.gakkai-web.net/jiasc/program/hp23/doc/program_symposium.pdf</a></li>
                    <li>&ldquo;Synergy-Based Motor Learning for Improving the Spatial and Temporal Generalization Ability,&rdquo; the 9th IEEJ international workshop on Sensing, Actuation, Motion Control, and Optimization (SAMCON2023), 2023-03-25.<br>URL <a href="http://www2.iee.or.jp/~diic/samcon/2023/program/program.html#S1569614018">http://www2.iee.or.jp/~diic/samcon/2023/program/program.html#S1569614018</a></li>
                    <li>&ldquo;ロボットの運動制御と深層学習技術の応用例,&rdquo; 日本結晶成長学会 新技術・新材料分科会 第2回研究会「新技術・新材料開発に向けたデータ駆動技術の応用」, 2023-03-03.<br>URL <a href="https://www.jacg.jp/jp/about/newtech/20230303.pdf">https://www.jacg.jp/jp/about/newtech/20230303.pdf</a></li>
                    <li>&ldquo;動作の時空間的構造を利用した模倣学習,&rdquo; 第69回 自律分散システム部会研究会「若手研究者による模倣学習・強化学習の新展開」, 2022-12-13. URL <a href="https://www.sice.or.jp/das/eventcalendar.html">https://www.sice.or.jp/das/eventcalendar.html</a></li>
                    <li>&ldquo;Motor Synergy Generalization Framework for New Targets in Multi-planar and Multi-directional Reaching Task,&rdquo; the 33rd 2022 International Symposium on Micro-NanoMechatronics and Human Science, 2022-11-28.<br>URL <a href="http://www.mein.nagoya-u.ac.jp/mhs/invited22.html">http://www.mein.nagoya-u.ac.jp/mhs/invited22.html</a></li>
                    <li>&ldquo;ロボットの運動制御における深層学習の応用,&rdquo; トライボロジー技術へのAIの活用を考える研究会 第2回研究会, 2021-08-31.<br>URL <a href="https://www.tribology.jp/unit/s-105/past.html">https://www.tribology.jp/unit/s-105/past.html</a></li>
                    <li>&ldquo;ニューラルネットワークを用いた動作特徴量の学習とロボットへの応用,&rdquo; SICE Tohoku オンライン講演会 ～東北地方の若手研究者と語り合う～, 2020-12-22.<br>URL <a href="https://www.topic.ad.jp/sice/htdocs/2020/online_lecture.pdf">https://www.topic.ad.jp/sice/htdocs/2020/online_lecture.pdf</a></li>
                </ol>
            </section>

            <section>
                <h2>Research funds</h2>

                <ol>
                    <li>2023年度, JST ACT-X「AI活用で挑む学問の革新と創成」加速フェーズ, &ldquo;Shared synergyを利用した高い汎化能力をもたらす模倣学習,&rdquo; 1700千円（総額）, 代表.</li>
                    <li>2022–2024年度, 日本学術振興会 若手研究, &ldquo;力覚情報に基づく複雑な道具形状と接触位置との効率的な同時推定,&rdquo; 3250千円（総額）, 代表.</li>
                    <li>2020–2022年度, JST ACT-X「AI活用で挑む学問の革新と創成」, &ldquo;Shared synergyを利用した高い汎化能力をもたらす模倣学習,&rdquo; 5500千円（総額）, 代表.</li>
                    <li>2018–2019年度, 日本学術振興会 特別研究員（DC2）, &ldquo;sequence-to-sequenceモデルを用いた臨機応変な物体操作,&rdquo; 1500千円（総額）, 代表.</li>
                <ol>
            </section>
        </section>

        <section id="contact">
            <h1>Contact</h1>

            <section>
                <h2>E-mail</h2>

                <p class="item">
                    <img src="mail.svg" alt="mail address">
                </p>
            </section>

            <section>
                <h2>Address</h2>

                <address class="item">
                    <a href="http://neuro.mech.tohoku.ac.jp/">Neuro-robotics lab (Hayashibe lab)</a><br>
                    Department of Robotics, Graduate School of Engineering, Tohoku University<br>
                    6-6-01 Aoba, Aramaki, Aoba-ku, Sendai, 980-8579 Japan
                </address>
            </section>

            <section>
                <h2>Links</h2>

                <p class="item">
                    Twitter: <a href="https://twitter.com/kyokutsuzawa">@kyokutsuzawa</a>
                </p>

                <p class="item">
                    Google scholar: <a href="https://scholar.google.co.jp/citations?user=5ojFABkAAAAJ">Profile</a>
                </p>

                <p class="item">
                    Scopus: <a href="https://www.scopus.com/authid/detail.uri?authorId=57193017750">Profile</a>
                </p>

                <p class="item">
                    Researchmap: <a href="https://researchmap.jp/kyo_kutsuzawa">Profile</a>
                </p>
            </section>
        </section>
    </main>
</body>
</html>
